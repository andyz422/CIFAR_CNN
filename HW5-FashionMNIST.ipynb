{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "TRAIN_SIZE, VAL_SIZE = 50000, 10000\n",
    "dataset_prefix = \"fashionmnist\" \n",
    "num_classes = 10\n",
    "\n",
    "train_data = np.load(\"./hw5_data/{}_train.npy\".format(dataset_prefix))\n",
    "test_data = np.load(\"./hw5_data/{}_test.npy\".format(dataset_prefix))\n",
    "\n",
    "# Note: I am unable to use sklearn at the moment due to package inconsistencies\n",
    "# Split train data to train/val/test\n",
    "train_images = train_data[:TRAIN_SIZE, :]\n",
    "val_images = train_data[TRAIN_SIZE:, :]\n",
    "\n",
    "test_images = test_data.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def imshow(image, title=None):\n",
    "    fig, ax = plt.subplots(1, figsize=(2,2))\n",
    "    ax.imshow(image.squeeze(0)*255, cmap='gray')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "for i in range(10):\n",
    "    imshow(train_images[i], title='Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# CNN ARCHITECTURE: Conv2d(,,5) -> MaxPool2d(2,2) -> ReLU -> Conv2d(,,5) -> MaxPool2d(2,2) -> Linear(,) -> ReLu \n",
    "# -> Linear(, 10) -> Softmax\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, S=1, P=0, conv1=(1, 10, 5), pool=2, pool_S=1, conv2=(10, 10, 5), fc1=20, fc2=10, drop=0.5, batch=1):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(conv1[0], conv1[1], conv1[2], stride=S, padding=P) # output dim=(BATCH_SIZE x c1 x (24+2P) x (24+2P))\n",
    "        self.pool = nn.MaxPool2d(pool, stride=pool_S) # output dim=(BATCH_SIZE x c1 x (12+P) x (12+P))\n",
    "        self.conv2 = nn.Conv2d(conv2[0], conv2[1], conv2[2], stride=1, padding=P) # output dim=(BATCH_SIZE x c2 x (8+3P) x (8+3P))\n",
    "        self.l = conv2[1] * (4+int(1.5*P)) * (4+int(1.5*P))\n",
    "        self.fc1 = nn.Linear(self.l, fc1, bias=True) \n",
    "        self.fc2 = nn.Linear(fc1, num_classes, bias=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=fc1)\n",
    "        self.batch = batch\n",
    "        print(self.batch)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.pool(self.dropout(self.conv1(x)))) # dim=(BATCH_SIZE x c1 x (12+P) x (12+P))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(self.batch, self.l)\n",
    "        x = self.fc1(x) \n",
    "        if self.batch > 1:\n",
    "            x = self.bn1(x)\n",
    "        x = self.softmax(self.fc2(F.relu(x)))\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:106: UserWarning: Pandas requires version '1.2.1' or newer of 'bottleneck' (version '1.1.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(S, P, conv1, pool, pool_S, conv2, fc1, drop, opt, lr, mom, batch):\n",
    "    # NN INITIALIZATION\n",
    "    net = Net(S=S, P=P, conv1=conv1, pool=pool, pool_S=pool_S, conv2=conv2, fc1=fc1, drop=drop, batch=batch)\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if opt == 'sgd':\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=mom)\n",
    "    elif opt == 'adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=lr, betas=(0.9,0.999))\n",
    "    elif opt == 'nesterov':\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=mom, nesterov=True)\n",
    "    \n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(train_images, batch_size=batch,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    epsilon = 0.002\n",
    "    losses = []\n",
    "    vals = []\n",
    "    for epoch in range(10):  # loop over the dataset multiple times \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data[:, :-1]\n",
    "            labels = data[:, -1]\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            if inputs.shape[0] == batch:\n",
    "                outputs = net(inputs.reshape(batch, 1, 28, 28).float())\n",
    "                outputs = outputs.reshape(batch, -1)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % (50000//(10*batch)) == ((50000//(10*batch))-1):    # print every 1/10 epoch\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / (50000//(10*batch))))\n",
    "                losses.append(running_loss/(50000//(10*batch)))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "                # val accuracy\n",
    "                valloader = torch.utils.data.DataLoader(val_images, batch_size=batch,\n",
    "                                                          shuffle=True, num_workers=2)\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    for data in valloader:\n",
    "                        images, labels = data[:, :-1], data[:, -1]\n",
    "                        if images.shape == (batch, 784):\n",
    "                            outputs = net(images.reshape(batch, 1, 28, 28).float())\n",
    "                            _, predicted = torch.max(outputs.data, 1)\n",
    "                            total += labels.size(0)\n",
    "                            correct += (predicted == labels).sum().item()\n",
    "\n",
    "                print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "                    100 * correct / total))\n",
    "                vals.append(100 * correct / total)\n",
    "                \n",
    "\n",
    "        if losses[-9] - losses[-1] < epsilon:\n",
    "            break\n",
    "\n",
    "    print('Finished Training')\n",
    "    return net, losses, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform random search to tune hyperparameters; more efficient than grid search since it allows for identifying important\n",
    "# parameters more quickly, and avoids prioritizing less important ones (Stanford CS231)\n",
    "\n",
    "def random_search(num_iter=1):\n",
    "    # S = 1 as good practice and simplified dimensional constraints\n",
    "    # pool = 2, pool_S=2 as convention according to cs231\n",
    "    # fc2 = 10 (num_labels) \n",
    "    pad = np.random.randint(1, 2, size=num_iter)*2 # since filter kernel is 5x5,P in {0,2,4}\n",
    "    c1 = 2**np.random.randint(9, 10, size=num_iter) # conv1 in [32, 512], kernel is 5x5\n",
    "    c2 = 2**np.random.randint(9, 10, size=num_iter) # conv2 in [32, 512], kernel is 5x5\n",
    "    fc1 = 2**np.random.randint(9, 10, size=num_iter) # fc1 in [32, 512]\n",
    "    opt_l = ['sgd', 'nesterov', 'adam'] # opt in {sgd, nesterov, adam}\n",
    "    opt = np.random.randint(2, 3, size=num_iter)\n",
    "    lr = np.random.randint(4, 5, size=num_iter) # lr in {0.001, 0.0001}\n",
    "    mom = np.random.uniform(0.7, 0.91, size=num_iter) # mom in [0.7, 0.99]\n",
    "    drop = np.random.uniform(0.4, 0.81, size=num_iter) # dropout in [0.2, 0.8]\n",
    "    batch = 2**(np.random.randint(6, 7, size=num_iter)) # batch in [16, 64]\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        net, losses, vals = train(S=1, P=pad[i], conv1=(1, c1[i], 5), pool=2, pool_S=2, conv2=(c1[i], c2[i], 5), \n",
    "                            fc1=fc1[i], drop=drop[i], opt=opt_l[opt[i]], lr=0.1**lr[i], mom=mom[i], batch=int(batch[i]))\n",
    "        print(\"Trained NN{:}\".format(i))\n",
    "        \n",
    "        # Save NN\n",
    "        PATH = 'fashionmnist/fashionmnist_net{:}.pth'.format(i)\n",
    "        torch.save(net.state_dict(), PATH)\n",
    "        \n",
    "        # Save losses\n",
    "        pd.DataFrame(losses).to_csv(\"fashionmnist/losses{:}.csv\".format(i))\n",
    "        pd.DataFrame(vals).to_csv(\"fashionmnist/vals{:}.csv\".format(i))\n",
    "        # Save parameters\n",
    "        with open('fashionmnist/params{:}.txt'.format(i), 'w+') as f:\n",
    "            f.write(\"{:}\\n opt: {:}\\n lr: {:}\\n mom: {:}\\n drop: {:}\\n batch: {:}\".format(net.parameters, opt_l[opt[i]], \n",
    "                                                                                          0.1**lr[i], mom[i], drop[i], batch[i]))\n",
    "        \n",
    "        print(\"Saved NN{:}\".format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "[1,    78] loss: 1.748\n",
      "Accuracy of the network on the 10000 test images: 81 %\n",
      "[1,   156] loss: 1.650\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "[1,   234] loss: 1.627\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "[1,   312] loss: 1.618\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "[1,   390] loss: 1.610\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "[1,   468] loss: 1.608\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "[1,   546] loss: 1.592\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "[1,   624] loss: 1.593\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "[1,   702] loss: 1.590\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "[1,   780] loss: 1.583\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "[2,    78] loss: 1.581\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "[2,   156] loss: 1.578\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[2,   234] loss: 1.567\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[2,   312] loss: 1.570\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[2,   390] loss: 1.570\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[2,   468] loss: 1.570\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[2,   546] loss: 1.559\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "[2,   624] loss: 1.569\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[2,   702] loss: 1.560\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[2,   780] loss: 1.558\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[3,    78] loss: 1.555\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[3,   156] loss: 1.555\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[3,   234] loss: 1.558\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[3,   312] loss: 1.555\n",
      "Accuracy of the network on the 10000 test images: 88 %\n",
      "[3,   390] loss: 1.554\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[3,   468] loss: 1.552\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[3,   546] loss: 1.554\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[3,   624] loss: 1.550\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[3,   702] loss: 1.554\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[3,   780] loss: 1.550\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[4,    78] loss: 1.540\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[4,   156] loss: 1.548\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[4,   234] loss: 1.542\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[4,   312] loss: 1.540\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[4,   390] loss: 1.549\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[4,   468] loss: 1.542\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[4,   546] loss: 1.547\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[4,   624] loss: 1.544\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[4,   702] loss: 1.541\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[4,   780] loss: 1.543\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[5,    78] loss: 1.540\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[5,   156] loss: 1.538\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[5,   234] loss: 1.533\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "[5,   312] loss: 1.530\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[5,   390] loss: 1.532\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[5,   468] loss: 1.539\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "[5,   546] loss: 1.536\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "[5,   624] loss: 1.533\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[5,   702] loss: 1.539\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[5,   780] loss: 1.535\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "[6,    78] loss: 1.530\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "[6,   156] loss: 1.524\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "[6,   234] loss: 1.525\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "[6,   312] loss: 1.530\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[6,   390] loss: 1.532\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "[6,   468] loss: 1.534\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "[6,   546] loss: 1.531\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "[6,   624] loss: 1.525\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[6,   702] loss: 1.531\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "[6,   780] loss: 1.530\n",
      "Accuracy of the network on the 10000 test images: 91 %\n",
      "Finished Training\n",
      "Trained NN0\n",
      "Saved NN0\n"
     ]
    }
   ],
   "source": [
    "random_search(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Accuracy of the network on the 10000 test images: 71 %\n"
     ]
    }
   ],
   "source": [
    "# TRAINING ON VALIDATION\n",
    "BATCH=64\n",
    "valloader = torch.utils.data.DataLoader(val_images, batch_size=BATCH,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "epsilon = 0.005\n",
    "losses = []\n",
    "vals = []\n",
    "for epoch in range(2):  # loop over the dataset multiple times \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(valloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data[:, :-1]\n",
    "        labels = data[:, -1]\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        if inputs.shape[0] == batch:\n",
    "            outputs = net(inputs.reshape(batch, 1, 28, 28).float())\n",
    "            outputs = outputs.reshape(batch, -1)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % (10000//(10*batch)) == ((10000//(10*batch))-1):    # print every 1/10 epoch\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / (10000//(10*batch))))\n",
    "            losses.append(running_loss/(10000//(10*batch)))\n",
    "            running_loss = 0.0\n",
    "                \n",
    "    if losses[-9] - losses[-1] < epsilon:\n",
    "        break\n",
    "\n",
    "print('Finished Training')\n",
    "print(\"Trained NN{:}\".format(i))\n",
    "        \n",
    "# Save NN\n",
    "PATH = 'fashionmnist/fashionmnist_net{:}.pth'.format(100)\n",
    "torch.save(net.state_dict(), PATH)\n",
    "        \n",
    "# Save losses\n",
    "pd.DataFrame(losses).to_csv(\"fashionmnist/losses{:}.csv\".format(100))\n",
    "pd.DataFrame(vals).to_csv(\"fashionmnist/vals{:}.csv\".format(100))\n",
    "        \n",
    "print(\"Saved NN{:}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n"
     ]
    }
   ],
   "source": [
    "# Load NN\n",
    "PATH = 'fashionmnist/fashionmnist_net{:}.pth'.format(11)\n",
    "BATCH = 64\n",
    "\n",
    "net = Net(S=1, P=0, conv1=(1,32,5), pool=2, pool_S=2, conv2=(32,512,5), fc1=128, drop=0.3539679254488697, batch=100)\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# predictions on test set\n",
    "testloader = torch.utils.data.DataLoader(test_images, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(testloader):\n",
    "        outputs = net(data.reshape(100, 1, 28, 28).float())\n",
    "        predictions.extend(torch.max(outputs.data, 1)[1])\n",
    "        print(i*100)\n",
    "        \n",
    "\n",
    "pd.DataFrame(predictions).to_csv(\"predictions2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
